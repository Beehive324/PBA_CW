{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0ec559-7e46-4421-98a9-9062c7dcc7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install keras\n",
    "!pip install pandas\n",
    "!pip install matplotlib\n",
    "!pip install sklearn\n",
    "!pip install seaborn\n",
    "!pip install tensorflow\n",
    "!pip install plotly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1c5783-71a0-499a-9d3f-f6175b4da66f",
   "metadata": {},
   "source": [
    "# Supervised ML Technique: Artificial Neural Networks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda0d3f0-0197-4b45-8cdd-2f1ce69ef142",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow\n",
    "\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c04624-6549-4f6d-a73f-4349824e34e2",
   "metadata": {},
   "source": [
    "## Iteration 1: Numerical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17db2b8a-d01c-4b9a-bca9-e505f00db25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Numerical Features\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv('/Users/constanciasoares/Downloads/cleanLoanData.csv')\n",
    "\n",
    "\n",
    "data.columns = data.columns.str.strip()\n",
    "\n",
    "# Display dataset columns for verification\n",
    "print(\"Dataset columns:\")\n",
    "print(data.columns)\n",
    "\n",
    "X = data.drop(columns=['Profession', 'STATE', 'Income_Level', 'Age_Group'])\n",
    "\n",
    "y = data['Risk_Flag']\n",
    "\n",
    "print(\"\\nFeatures (X):\")\n",
    "print(X.head())\n",
    "\n",
    "print(\"\\nTarget (y):\")\n",
    "print(y.head())\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "print(X)\n",
    "print(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab16a37b-e4bb-425f-a076-aafb0f014192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the distribution of the target variable\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.countplot(x=y)\n",
    "plt.title('Distribution of Risk_Flag (Target)')\n",
    "plt.show()\n",
    "\n",
    "# Print the class distribution\n",
    "print(y.value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9812bcbd-b293-4f1e-912c-ac4605b517fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Train a random forest to check feature importance\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Plot feature importances\n",
    "feature_importances = rf_model.feature_importances_\n",
    "features = X.columns\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x=feature_importances, y=features)\n",
    "plt.title('Feature Importance')\n",
    "plt.show()\n",
    "plt.savefig('importance.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7e0512-5957-483d-b777-307ca9ec965e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = X.shape[1]\n",
    "print(num_features) #get number of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf5721f-8947-4f28-b8a9-8be21661ef37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import numpy as np\n",
    "\n",
    "# Sequential Model\n",
    "model = Sequential()\n",
    "\n",
    "# Build the model with hyperparameters (placeholders)\n",
    "model.add(Dense(num_features,activation=\"relu\"))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(39, activation=\"relu\"))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Dense(19, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ed386b-02b7-47ef-a54b-2168afdc6df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    epochs=100, \n",
    "    validation_data=(X_test, y_test),\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d3c81a-2d6d-4967-843e-29d7e344f7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test, verbose=0)\n",
    "print(y_pred)\n",
    "binary_predictions = (y_pred >= 0.5).astype(int)\n",
    "print(binary_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0193e77e-8218-4314-a8b2-147c7d64e70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test, verbose=0)\n",
    "print(y_pred)\n",
    "binary_predictions = (y_pred >= 0.5).astype(int)\n",
    "print(binary_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb110b5b-461a-427f-b6f5-02c7332e8129",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Calculate the ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, binary_predictions)\n",
    "\n",
    "# Calculate the AUC\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot the ROC curve\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b1768b-850f-436c-bf16-472cf929058f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training Accuracy:\", history.history['accuracy'][-1])\n",
    "print(\"Validation Accuracy:\", history.history['val_accuracy'][-1])\n",
    "print(\"Loss:\", history.history['loss'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07df938-4d1c-404c-929b-a0312cca0611",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "cm = confusion_matrix(y_test, binary_predictions)\n",
    "    \n",
    "# Create figure\n",
    "plt.figure(figsize=(8, 6))\n",
    "    \n",
    "# Plot heatmap\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',xticklabels='auto')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.show()\n",
    "    \n",
    "# Print classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, binary_predictions, target_names= None))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c088bde-c575-45c5-8492-3b24b0088522",
   "metadata": {},
   "source": [
    "## Iteration 2: Top 5 Most Important Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87e25ae-0a88-4753-98e7-17b6836e3986",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Top 5 Most Important Features\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "data = pd.read_csv('/Users/constanciasoares/Downloads/cleanLoanData.csv')\n",
    "data.columns = data.columns.str.strip()\n",
    "\n",
    "# One-Hot Encode \n",
    "data_encoded = pd.get_dummies(data, columns=['STATE', 'Married.Single', 'House_Ownership', 'Age_Group', 'Income_Level' ], drop_first=True)\n",
    "\n",
    "\n",
    "data_encoded = data_encoded.loc[:, ~data_encoded.columns.str.startswith('Profession')]\n",
    "data_encoded = data_encoded.loc[:, ~data_encoded.columns.str.startswith('STATE')]\n",
    "\n",
    "# Now we include all features, except 'Risk_Flag' and 'Profession since Profession is already one-hot encoded'\n",
    "X = data[['Income','Age','Experience','CURRENT_JOB_YRS', 'ESI']]\n",
    "\n",
    "y = data['Risk_Flag']  \n",
    "\n",
    "\n",
    "\n",
    "# Verify the changes by printing the columns\n",
    "print(data_encoded.columns)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "print(\"Features (X):\")\n",
    "print(X.head())\n",
    "\n",
    "print(\"\\nTarget (y):\")\n",
    "print(y.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0853166c-2b9d-446f-88a7-4737558141d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 66"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e6cf25-20bc-4c1e-ad96-f25b09ffbae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import numpy as np\n",
    "\n",
    "# Sequential Model\n",
    "model = Sequential()\n",
    "\n",
    "# Build the model with hyperparameters (placeholders)\n",
    "model.add(Dense(num_features,activation=\"relu\"))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(39, activation=\"relu\"))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Dense(19, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a69b6b6-c51b-4c89-982c-023156dbf21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    epochs=100, \n",
    "    validation_data=(X_test, y_test),\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2796fd-5408-4704-a40f-b7aae7b1c0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test, verbose=0)\n",
    "print(y_pred)\n",
    "binary_predictions = (y_pred >= 0.5).astype(int)\n",
    "print(binary_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73879edb-727d-4c72-a98d-a0f58ecafcae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Calculate the ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, binary_predictions)\n",
    "\n",
    "# Calculate the AUC\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot the ROC curve\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(\"Training Accuracy:\", history.history['accuracy'][-1])\n",
    "print(\"Validation Accuracy:\", history.history['val_accuracy'][-1])\n",
    "print(\"Loss:\", history.history['loss'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8717d4ef-d667-46a5-900e-df3d5d17558a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "cm = confusion_matrix(y_test, binary_predictions)\n",
    "    \n",
    "# Create figure\n",
    "plt.figure(figsize=(8, 6))\n",
    "    \n",
    "# Plot heatmap\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',xticklabels='auto')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.show()\n",
    "    \n",
    "# Print classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, binary_predictions, target_names= None))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273e0474-1c00-4e94-ae14-6b1a5e26da27",
   "metadata": {},
   "source": [
    "## Iteration 3: Numerical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48109cd2-0f96-4614-9c39-2c8cea928e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#All features \n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "data = pd.read_csv('/Users/constanciasoares/Downloads/cleanLoanData.csv')\n",
    "data.columns = data.columns.str.strip()\n",
    "\n",
    "# One-Hot Encode \n",
    "data_encoded = pd.get_dummies(data, columns=['STATE', 'Married.Single', 'House_Ownership', 'Age_Group', 'Income_Level' ], drop_first=True)\n",
    "\n",
    "\n",
    "data_encoded = data_encoded.loc[:, ~data_encoded.columns.str.startswith('Profession')]\n",
    "data_encoded = data_encoded.loc[:, ~data_encoded.columns.str.startswith('STATE')]\n",
    "\n",
    "# Now we include all features, except 'Risk_Flag' and 'Profession since Profession is already one-hot encoded'\n",
    "X = data_encoded.drop(columns=['Risk_Flag'])\n",
    "\n",
    "y = data['Risk_Flag']  \n",
    "\n",
    "\n",
    "\n",
    "# Verify the changes by printing the columns\n",
    "print(data_encoded.columns)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "print(\"Features (X):\")\n",
    "print(X.head())\n",
    "\n",
    "print(\"\\nTarget (y):\")\n",
    "print(y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57bed3c-6631-436e-9ab9-d98554643679",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import numpy as np\n",
    "\n",
    "# Sequential Model\n",
    "model = Sequential()\n",
    "\n",
    "# Build the model with hyperparameters (placeholders)\n",
    "model.add(Dense(num_features,activation=\"relu\"))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(39, activation=\"relu\"))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Dense(19, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21923098-a364-4cf7-8885-1c404561f798",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    epochs=100, \n",
    "    validation_data=(X_test, y_test),\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08bf318a-f69a-4455-8fa7-261fb9c9b7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Calculate the ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, binary_predictions)\n",
    "\n",
    "# Calculate the AUC\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot the ROC curve\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(\"Training Accuracy:\", history.history['accuracy'][-1])\n",
    "print(\"Validation Accuracy:\", history.history['val_accuracy'][-1])\n",
    "print(\"Loss:\", history.history['loss'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512fbbbe-2e27-4efe-96cf-50764778234e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "cm = confusion_matrix(y_test, binary_predictions)\n",
    "    \n",
    "# Create figure\n",
    "plt.figure(figsize=(8, 6))\n",
    "    \n",
    "# Plot heatmap\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',xticklabels='auto')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.show()\n",
    "    \n",
    "# Print classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, binary_predictions, target_names= None))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768eedeb-d33e-4132-9c37-96baa10c2aed",
   "metadata": {},
   "source": [
    "# Supervised ML Technique: Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4daace9b-c3df-485f-b203-92bc0a8379a9",
   "metadata": {},
   "source": [
    "### Data Set Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9442d8-5609-422b-a910-090c8a39a953",
   "metadata": {},
   "outputs": [],
   "source": [
    "#All features \n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "data = pd.read_csv('/Users/constanciasoares/Downloads/cleanLoanData.csv')\n",
    "data.columns = data.columns.str.strip()\n",
    "\n",
    "# One-Hot Encode \n",
    "data_encoded = pd.get_dummies(data, columns=['STATE', 'Married.Single', 'House_Ownership', 'Age_Group', 'Income_Level' ], drop_first=True)\n",
    "\n",
    "\n",
    "data_encoded = data_encoded.loc[:, ~data_encoded.columns.str.startswith('Profession')]\n",
    "data_encoded = data_encoded.loc[:, ~data_encoded.columns.str.startswith('STATE')]\n",
    "\n",
    "# Now we include all features, except 'Risk_Flag' and 'Profession since Profession is already one-hot encoded'\n",
    "X = data_encoded.drop(columns=['Risk_Flag'])\n",
    "\n",
    "y = data['Risk_Flag']  \n",
    "\n",
    "\n",
    "\n",
    "# Verify the changes by printing the columns\n",
    "print(data_encoded.columns)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "print(\"Features (X):\")\n",
    "print(X.head())\n",
    "\n",
    "print(\"\\nTarget (y):\")\n",
    "print(y.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c116a112-e77a-4626-8579-664a6538b0c0",
   "metadata": {},
   "source": [
    "### Iteration 1: Baseline Model With All Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4703572-b049-4fee-9a05-21b3e351f801",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Initialize the RandomForestClassifier\n",
    "rfmodel = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "# Train the model\n",
    "rfmodel.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set (X_test, not X_cv)\n",
    "rfpredictions = rfmodel.predict(X_test)\n",
    "\n",
    "# Print the accuracy score\n",
    "print(\"Accuracy Score:\")\n",
    "print(accuracy_score(y_test, rfpredictions))\n",
    "\n",
    "# Print the classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, rfpredictions))\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, rfpredictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92ca21f-0226-48b6-9208-24e10b8e1a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, rfpredictions)\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['No Risk', 'Risky'], yticklabels=['No Risk', 'Risky'])\n",
    "\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd90a103-b8e8-4dd0-b5d5-14c0a33866e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "rfmodel = RandomForestClassifier(n_estimators=200, random_state=42)  # Create the model instance\n",
    "rfmodel.fit(X_train, y_train)  # Train the model with the training data\n",
    "\n",
    "rfprobs = rfmodel.predict_proba(X_test)[:, 1]  # Probabilities for the positive class\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, rfprobs)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='green', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')  # Diagonal line for random guessing\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31399e82-adea-4ff4-b54e-e3ec02a8e230",
   "metadata": {},
   "source": [
    "### Iteration 2: Hyperparameter Tuning with Top 5 Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2bdfab9-72c2-42ea-b2a2-e2023783942f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Top 5 Most Important Features\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "data = pd.read_csv('/Users/constanciasoares/Downloads/cleanLoanData.csv')\n",
    "data.columns = data.columns.str.strip()\n",
    "\n",
    "# One-Hot Encode \n",
    "data_encoded = pd.get_dummies(data, columns=['STATE', 'Married.Single', 'House_Ownership', 'Age_Group', 'Income_Level' ], drop_first=True)\n",
    "\n",
    "\n",
    "data_encoded = data_encoded.loc[:, ~data_encoded.columns.str.startswith('Profession')]\n",
    "data_encoded = data_encoded.loc[:, ~data_encoded.columns.str.startswith('STATE')]\n",
    "\n",
    "# Now we include all features, except 'Risk_Flag' and 'Profession since Profession is already one-hot encoded'\n",
    "X = data[['Income','Age','Experience','CURRENT_JOB_YRS', 'ESI']]\n",
    "\n",
    "y = data['Risk_Flag']  \n",
    "\n",
    "\n",
    "\n",
    "# Verify the changes by printing the columns\n",
    "print(data_encoded.columns)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "print(\"Features (X):\")\n",
    "print(X.head())\n",
    "\n",
    "print(\"\\nTarget (y):\")\n",
    "print(y.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850a6e4c-1e64-44b8-98bb-3bf04e84deb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve, auc\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Define the parameter distribution for randomized search\n",
    "param_dist = {\n",
    "    'n_estimators': [100, 200, 300, 400, 500],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# Initialize the RandomForestClassifier\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Use RandomizedSearchCV instead of GridSearchCV for faster computation\n",
    "random_search = RandomizedSearchCV(estimator=rf_model, param_distributions=param_dist,\n",
    "                                   n_iter=10, cv=3, n_jobs=-1, random_state=42, verbose=2)\n",
    "\n",
    "# Fit the model with randomized search to find the best hyperparameters\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and the best model\n",
    "best_params = random_search.best_params_\n",
    "best_model = random_search.best_estimator_\n",
    "\n",
    "# Print the best parameters\n",
    "print(\"Best Hyperparameters from RandomizedSearchCV:\")\n",
    "print(best_params)\n",
    "\n",
    "# Make predictions on the test set using the best model\n",
    "rf_predictions = best_model.predict(X_test)\n",
    "\n",
    "# Print accuracy score\n",
    "print(\"\\nAccuracy Score:\")\n",
    "print(accuracy_score(y_test, rf_predictions))\n",
    "\n",
    "# Print classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, rf_predictions))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, rf_predictions))\n",
    "\n",
    "# Predict probabilities for the positive class (class 1)\n",
    "y_prob = best_model.predict_proba(X_test)[:, 1]  # probabilities for class 1\n",
    "\n",
    "# Compute ROC curve and AUC (Area Under the Curve)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')  # Diagonal line (random classifier)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba1992b-c615-4875-9947-149295912411",
   "metadata": {},
   "source": [
    "### Iteration 3: Ensemble Approach (Bagging) with Full Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac48f900-668f-45a7-b24f-0261d418e13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# Create a Bagging model with Decision Trees as base learners\n",
    "bagging_model = BaggingClassifier(estimator=DecisionTreeClassifier(), \n",
    "                                 n_estimators=350, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "bagging_model.fit(X_train, y_train)\n",
    "\n",
    "y_prob = bagging_model.predict_proba(X_test)[:, 1]  # probabilities for class 1\n",
    "\n",
    "# Compute ROC curve and AUC (Area Under the Curve)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot the ROC curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='green', lw=2, label=f'ROC curve (area = {roc_auc:.5f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')  # Diagonal line (random classifier)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Iteration 3: Ensemble Approach (Bagging) with Full Features')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
