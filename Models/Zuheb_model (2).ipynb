{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "import pandas as pd\nimport matplotlib.pyplot as plt\n#import seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report, accuracy_score, roc_curve, auc, confusion_matrix\n\n\nfile_path = 'cleanLoanData.csv'\ndata = pd.read_csv(file_path)\n\n# Features\nfeatures = [\n    'Married.Single', 'House_Ownership', 'Car_Ownership', \n    'Profession', 'STATE', 'Income_Level', 'Age_Group'\n]\ntarget = 'Risk_Flag'\n\n\ncategorical_features = ['Profession', 'STATE', 'Income_Level', 'Age_Group']\ndata = pd.get_dummies(data, columns=categorical_features, drop_first=True)\n\n\nif target not in data.columns:\n    raise ValueError(f\"The target column '{target}' does not exist in the dataset.\")\n\n\nX = data.drop(columns=[target])\ny = data[target]\n\n# Traning set 70/30\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\n\nrf_model = RandomForestClassifier(random_state=42)\nrf_model.fit(X_train, y_train)\n\n\ny_pred_prob = rf_model.predict_proba(X_test)[:, 1]\ny_pred = rf_model.predict(X_test)\n\naccuracy = accuracy_score(y_test, y_pred)\nclassification_report_output = classification_report(y_test, y_pred)\n\n#confusion matrix\n#conf_matrix = confusion_matrix(y_test, y_pred)\n\n# Plot the confusion matrix\n#plt.figure(figsize=(8, 6))\n#sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"No Risk\", \"Risk\"], yticklabels=[\"No Risk\", \"Risk\"])\n#plt.xlabel('Predicted')\n#plt.ylabel('Actual')\n#plt.title('Confusion Matrix')\n#plt.show()\n\n\nfeature_importances = pd.DataFrame({\n    'Feature': X_train.columns,\n    'Importance': rf_model.feature_importances_\n})\n\n# Combine one-hot encoded features\nfeature_importances['Category'] = feature_importances['Feature'].apply(\n    lambda x: 'Profession' if 'Profession' in x else \n              ('STATE' if 'STATE' in x else \n               ('Income_Level' if 'Income_Level' in x else \n                ('Age_Group' if 'Age_Group' in x else x)))\n)\n\n# Filter to include only the specified columns\nfiltered_features = ['Married.Single', 'House_Ownership', 'Car_Ownership', \n                     'Profession', 'STATE', 'Income_Level', 'Age_Group']\naggregated_importances = feature_importances[\n    feature_importances['Category'].isin(filtered_features)\n].groupby('Category')['Importance'].sum().reset_index()\n\n# Sort aggregated feature importance\naggregated_importances = aggregated_importances.sort_values(by='Importance', ascending=False)\n\n# Plot aggregated feature importance\nplt.figure(figsize=(10, 6))\nplt.barh(aggregated_importances['Category'], aggregated_importances['Importance'], color='skyblue')\nplt.xlabel('Feature Importance')\nplt.ylabel('Feature Category')\nplt.title('Aggregated Feature Importance Plot')\nplt.gca().invert_yaxis()\nplt.grid(axis='x')\nplt.show()\n\n# Plot the ROC curve\nfpr, tpr, _ = roc_curve(y_test, y_pred_prob)\nroc_auc = auc(fpr, tpr)\n\nplt.figure(figsize=(10, 6))\nplt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\nplt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--', label='Random Guess')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver Operating Characteristic (ROC) Curve')\nplt.legend(loc=\"lower right\")\nplt.grid()\nplt.show()\n\n# Display outputs\nprint(\"Filtered Aggregated Feature Importances:\")\nprint(aggregated_importances)\nprint(\"\\nConfusion Matrix:\")\n#print(conf_matrix)\nprint(\"\\nModel Evaluation:\")\nprint(f\"Accuracy: {accuracy}\")\nprint(\"Classification Report:\")\nprint(classification_report_output)\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_auc_score, roc_curve\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import roc_auc_score, roc_curve\n#import seaborn as sns\n\n\ndata_path = 'cleanLoanData.csv'  # Adjust this to the dataset's location\ndata = pd.read_csv(data_path)\n\n#Filter relevant columns\nselected_features = [\n      'Married.Single', 'House_Ownership',\n    'Car_Ownership', 'Profession', 'STATE',\n    'Risk_Flag', 'Income_Level', 'Age_Group', \n]\ndata = data[selected_features]\n\n\ncategorical_columns = data.select_dtypes(include=['object']).columns\n\n\nlabel_encoders = {}\nfor col in categorical_columns:\n    label_encoders[col] = LabelEncoder()\n    data[col] = label_encoders[col].fit_transform(data[col])\n\n\nX = data.drop('Risk_Flag', axis=1).values  # Features\ny = data['Risk_Flag'].values  # Target\n\n# Perform 70/30 split for training \nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\ns\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n#Train SVM \nsvm_model = SVC(kernel='linear', random_state=42, probability=True)\nsvm_model.fit(X_train_scaled, y_train)\n\n#\n# ROC Curve\nroc_auc = roc_auc_score(y_test, svm_model.decision_function(X_test_scaled))\nprint(f\"ROC AUC Score: {roc_auc}\")\n\nfpr, tpr, thresholds = roc_curve(y_test, svm_model.decision_function(X_test_scaled))\nplt.figure()\nplt.plot(fpr, tpr, label=f'ROC Curve (AUC = {roc_auc:.2f})')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver Operating Characteristic Curve')\nplt.legend()\nplt.grid()\nplt.show()\ny_test_pred = svm_model.predict(X_test_scaled)\ntest_accuracy = accuracy_score(y_test, y_test_pred)\nprint(\"Testing Data Accuracy:\", test_accuracy)\nprint(\"\\nConfusion Matrix (Testing Data):\")\nprint(confusion_matrix(y_test, y_test_pred))\nprint(\"\\nClassification Report (Testing Data):\")\nprint(classification_report(y_test, y_test_pred))\n\n# Step 9: Generate Confusion Matrix done locally\n#cm = confusion_matrix(y_test, y_test_pred)\n#plt.figure()\n#sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Non-Risky', 'Risky'], yticklabels=['Non-Risky', 'Risky'])\n#plt.xlabel('Predicted')\n#plt.ylabel('Actual')\n#plt.title('Confusion Matrix')\n#plt.show()\n\n# Step 10: Generate and plot the ROC Curve\nroc_auc = roc_auc_score(y_test, svm_model.decision_function(X_test_scaled))\nprint(f\"ROC AUC Score: {roc_auc}\")\n\nfpr, tpr, thresholds = roc_curve(y_test, svm_model.decision_function(X_test_scaled))\nplt.figure()\nplt.plot(fpr, tpr, label=f'ROC Curve (AUC = {roc_auc:.2f})')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver Operating Characteristic Curve')\nplt.legend()\nplt.grid()\nplt.show()\n\n\nfeature_importance = svm_model.coef_[0]\nfeature_names = data.drop('Risk_Flag', axis=1).columns\n\n#feature importance\nfor name, importance in zip(feature_names, feature_importance):\n    print(f\"Feature: {name}, Importance: {importance:.4f}\")\n\n# Plot feature importance\nplt.figure()\nplt.barh(feature_names, feature_importance)\nplt.xlabel('Coefficient Value')\nplt.ylabel('Features')\nplt.title('Feature Importance via SVM Coefficients')\nplt.show()\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}